{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import random\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# Reading the dataset.\n",
    "# ====================================\n",
    "\n",
    "aisles = pd.read_csv('data/aisles.csv')\n",
    "\n",
    "departments = pd.read_csv('data/departments.csv')\n",
    "\n",
    "# We are defining the type of each column to optimize the storage as far as we can.\n",
    "priors = pd.read_csv('data/order_products__prior.csv',\n",
    "                     dtype={\n",
    "                         'order_id': np.int32,\n",
    "                         'product_id': np.uint16,\n",
    "                         'add_to_cart_order': np.int16,  # The order of an added item to the cart.\n",
    "                         'reordered': np.int8}  # Whether the item has been reordered in the past.\n",
    "                     )\n",
    "\n",
    "train = pd.read_csv('data/order_products__train.csv',\n",
    "                    dtype={\n",
    "                        'order_id': np.int32,\n",
    "                        'product_id': np.uint16,\n",
    "                        'add_to_cart_order': np.int16,\n",
    "                        'reordered': np.int8}\n",
    "                    )\n",
    "\n",
    "orders = pd.read_csv('data/orders.csv',\n",
    "                     dtype={\n",
    "                         'order_id': np.int32,\n",
    "                         'user_id': np.int32,\n",
    "                         'eval_set': 'category',  # Categorical column.\n",
    "                         'order_number': np.int16,\n",
    "                         'order_dow': np.int8,\n",
    "                         'order_hour_of_day': np.int8,\n",
    "                         'days_since_prior_order': np.float32},\n",
    "                     )\n",
    "\n",
    "products = pd.read_csv('data/products.csv',\n",
    "                       dtype={\n",
    "                           'product_id': np.uint16,\n",
    "                           'order_id': np.int32,\n",
    "                           'aisle_id': np.uint8,\n",
    "                           'department_id': np.uint},\n",
    "                       usecols=['product_id', 'aisle_id', 'department_id']  # Ignore the product Name., It's not \n",
    "                       # required in our case \n",
    "                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32434489, 4)\n(1384617, 4)\n(49688, 3)\n(32434489, 4)\n(3421083, 7)\n\n=======Priors table head=======\n\n   order_id  product_id  add_to_cart_order  reordered\n0         2       33120                  1          1\n1         2       28985                  2          1\n2         2        9327                  3          0\n3         2       45918                  4          1\n4         2       30035                  5          0\n5         2       17794                  6          1\n6         2       40141                  7          1\n\n=======Train table head=======\n\n   order_id  product_id  add_to_cart_order  reordered\n0         1       49302                  1          1\n1         1       11109                  2          1\n2         1       10246                  3          0\n3         1       49683                  4          0\n4         1       43633                  5          1\n5         1       13176                  6          0\n6         1       47209                  7          0\n\n=======Orders table head=======\n\n   order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n0   2539329        1    prior             1          2                  8   \n1   2398795        1    prior             2          3                  7   \n2    473747        1    prior             3          3                 12   \n3   2254736        1    prior             4          4                  7   \n4    431534        1    prior             5          4                 15   \n5   3367565        1    prior             6          2                  7   \n6    550135        1    prior             7          1                  9   \n\n   days_since_prior_order  \n0                     NaN  \n1                    15.0  \n2                    21.0  \n3                    29.0  \n4                    28.0  \n5                    19.0  \n6                    20.0  \n\n=======Products table head=======\n\n   product_id  aisle_id  department_id\n0           1        61             19\n1           2       104             13\n2           3        94              7\n3           4        38              1\n4           5         5             13\n5           6        11             11\n6           7        98              7\n"
     ]
    }
   ],
   "source": [
    "# Print some information about the dataset.\n",
    "print(priors.shape)\n",
    "print(train.shape)\n",
    "print(products.shape)\n",
    "print(priors.shape)\n",
    "print(orders.shape)\n",
    "\n",
    "print(\"\\n=======Priors table head=======\\n\")\n",
    "print(priors.head(n=7))\n",
    "\n",
    "print(\"\\n=======Train table head=======\\n\")\n",
    "print(train.head(n=7))\n",
    "\n",
    "print(\"\\n=======Orders table head=======\\n\")\n",
    "print(orders.head(n=7))\n",
    "\n",
    "print(\"\\n=======Products table head=======\\n\")\n",
    "print(products.head(n=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n=======Products table isNan checks =======\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_id       0\naisle_id         0\ndepartment_id    0\ndtype: int64\n\n=======Train table isNan checks =======\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id             0\nproduct_id           0\nadd_to_cart_order    0\nreordered            0\ndtype: int64\n\n=======Priors table isNan checks =======\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id             0\nproduct_id           0\nadd_to_cart_order    0\nreordered            0\ndtype: int64\n\n=======Orders table isNan checks =======\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                  0\nuser_id                   0\neval_set                  0\norder_number              0\norder_dow                 0\norder_hour_of_day         0\ndays_since_prior_order    0\ndtype: int64\nNans percentage: 6.03%\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# Data Cleaning.\n",
    "# ====================================\n",
    "\n",
    "orders.set_index('order_id', drop=False, inplace=True)  # inplace means don't create a new object\n",
    "products.set_index('product_id', drop=False, inplace=True)  # inplace means don't create a new object\n",
    "\n",
    "# Checking and removing Nans if found.\n",
    "print(\"\\n=======Products table isNan checks =======\\n\")\n",
    "print(np.sum(pd.isna(products)))\n",
    "\n",
    "print(\"\\n=======Train table isNan checks =======\\n\")\n",
    "print(np.sum(pd.isna(train)))\n",
    "\n",
    "print(\"\\n=======Priors table isNan checks =======\\n\")\n",
    "print(np.sum(pd.isna(priors)))\n",
    "\n",
    "print(\"\\n=======Orders table isNan checks =======\\n\")\n",
    "print(np.sum(pd.isna(orders)))\n",
    "\n",
    "# Found Nans only in the days_since_prior_order column in the orders table and replacing.\n",
    "print(\"Nans percentage: %.2f%%\" % (206209 / 3421083 * 100))\n",
    "orders['days_since_prior_order'] = orders['days_since_prior_order'].fillna(np.mean(orders['days_since_prior_order']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pandas/core/frame.py:6336: FutureWarning: 'product_id' is both an index level and a column label.\nDefaulting to column, but this will raise an ambiguity error in a future version\n  rsuffix=rsuffix, sort=sort)\n"
     ]
    }
   ],
   "source": [
    "# Approach два\n",
    "# ====================================\n",
    "\n",
    "# ====================================\n",
    "# Adding Features to Products.\n",
    "# ====================================\n",
    "\n",
    "# Add New Features to the Products table.\n",
    "# The reorder rate.\n",
    "prod_features = pd.DataFrame()\n",
    "prod_features['freq'] = priors.groupby(priors.product_id).size().astype(np.int32)\n",
    "prod_features['reorder_freq'] = priors.reordered.groupby(priors.product_id).sum().astype(np.int32)\n",
    "prod_features['reorder_rate'] = (prod_features.reorder_freq / prod_features.freq).astype(np.float)\n",
    "\n",
    "products = products.join(prod_features, on='product_id')\n",
    "\n",
    "del prod_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join prior with orders\n",
    "priors = priors.join(orders, on='order_id', rsuffix='_')\n",
    "priors.drop('order_id_', axis=1, inplace=True)  # Remove the order_id_ redundant column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# Adding Features to Users.\n",
    "# ====================================\n",
    "\n",
    "usrs = pd.DataFrame()\n",
    "usrs['avg_between_interval'] = orders.groupby('user_id')['days_since_prior_order'].mean().astype(np.float)\n",
    "usrs['orders_count'] = orders.groupby('user_id').size().astype(np.int16)\n",
    "usrs['avg_hour'] = orders.groupby('user_id')['order_hour_of_day'].mean().astype(np.int16)\n",
    "\n",
    "users = pd.DataFrame()\n",
    "users['total_items'] = priors.groupby('user_id').size().astype(np.int16)\n",
    "users['all_products'] = priors.groupby('user_id')['product_id'].apply(set)\n",
    "users['all_distinct_products'] = users.all_products.map(len).astype(np.int16)\n",
    "\n",
    "users = users.join(usrs)\n",
    "del usrs\n",
    "\n",
    "users['average_basket'] = (users.total_items / users.orders_count).astype(np.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add product id related to each user\n",
    "priors['user_product'] = priors.product_id + priors.user_id * 1000000\n",
    "\n",
    "# Creating a list of unique products bought by each user and the last time the user has bought it.\n",
    "dic = dict()\n",
    "for record in priors.itertuples():\n",
    "    user_product_id = record.user_product\n",
    "    if user_product_id not in dic:\n",
    "        dic[user_product_id] = (1,  # means bought once\n",
    "                                (record.order_number, record.order_id),\n",
    "                                record.add_to_cart_order\n",
    "                                )\n",
    "    else:\n",
    "        dic[user_product_id] = (dic[user_product_id][0] + 1,\n",
    "                                max(dic[user_product_id][1], (record.order_number, record.order_id)),\n",
    "                                dic[user_product_id][2] + record.add_to_cart_order\n",
    "                                )\n",
    "\n",
    "user_product = pd.DataFrame.from_dict(dic,\n",
    "                                      orient='index')  # Index means that the keys of the dictionary should be the \n",
    "# rows not columns\n",
    "\n",
    "del dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_product.columns = ['orders_count', 'last_order_id', 'sum_pos_in_cart']\n",
    "user_product.orders_count = user_product.orders_count.astype(np.int16)\n",
    "user_product.last_order_id = user_product.last_order_id.map(lambda x: x[1]).astype(np.int32)\n",
    "user_product.sum_pos_in_cart = user_product.sum_pos_in_cart.astype(np.int16)\n",
    "\n",
    "# Printing some stats\n",
    "print(\"UserProduct table shape and first 7 rows\")\n",
    "print(user_product.shape)\n",
    "print(user_product.head(n=7))\n",
    "\n",
    "# We are not now in the need of the priors table.\n",
    "del priors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# Creating Training and Testing splits.\n",
    "# ====================================\n",
    "\n",
    "train = orders[orders.eval_set == 'train']\n",
    "test = orders[orders.eval_set == 'test']\n",
    "\n",
    "train.set_index(['order_id', 'prod'], inplace=True, drop=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(selected_orders, train=False):\n",
    "    print('build candidate list')\n",
    "    order_list = []\n",
    "    product_list = []\n",
    "    labels = []\n",
    "    i = 0\n",
    "\n",
    "    for row in selected_orders.itertuples():\n",
    "        i += 1\n",
    "        if i % 10000 == 0: print('order row', i)\n",
    "        order_id = row.order_id\n",
    "        user_id = row.user_id\n",
    "        user_products = users.all_products[user_id]\n",
    "        product_list += user_products\n",
    "        order_list += [order_id] * len(user_products)\n",
    "        if labels_given:\n",
    "            labels += [(order_id, product) in train.index for product in user_products]\n",
    "\n",
    "    df = pd.DataFrame({'order_id': order_list, 'product_id': product_list}, dtype=np.int32)\n",
    "    labels = np.array(labels, dtype=np.int8)\n",
    "    del order_list\n",
    "    del product_list\n",
    "\n",
    "    print('user related features')\n",
    "    df['user_id'] = df.order_id.map(orders.user_id)\n",
    "    df['user_total_orders'] = df.user_id.map(users.nb_orders)\n",
    "    df['user_total_items'] = df.user_id.map(users.total_items)\n",
    "    df['total_distinct_items'] = df.user_id.map(users.total_distinct_items)\n",
    "    df['user_average_days_between_orders'] = df.user_id.map(users.average_days_between_orders)\n",
    "    df['user_average_basket'] = df.user_id.map(users.average_basket)\n",
    "\n",
    "    print('order related features')\n",
    "    # df['dow'] = df.order_id.map(orders.order_dow)\n",
    "    df['order_hour_of_day'] = df.order_id.map(orders.order_hour_of_day)\n",
    "    df['days_since_prior_order'] = df.order_id.map(orders.days_since_prior_order)\n",
    "    df['days_since_ratio'] = df.days_since_prior_order / df.user_average_days_between_orders\n",
    "\n",
    "    print('product related features')\n",
    "    df['aisle_id'] = df.product_id.map(products.aisle_id)\n",
    "    df['department_id'] = df.product_id.map(products.department_id)\n",
    "    df['product_orders'] = df.product_id.map(products.orders).astype(np.int32)\n",
    "    df['product_reorders'] = df.product_id.map(products.reorders)\n",
    "    df['product_reorder_rate'] = df.product_id.map(products.reorder_rate)\n",
    "\n",
    "    print('user_X_product related features')\n",
    "    df['z'] = df.user_id * 100000 + df.product_id\n",
    "    df.drop(['user_id'], axis=1, inplace=True)\n",
    "    df['UP_orders'] = df.z.map(userXproduct.nb_orders)\n",
    "    df['UP_orders_ratio'] = (df.UP_orders / df.user_total_orders).astype(np.float32)\n",
    "    df['UP_last_order_id'] = df.z.map(userXproduct.last_order_id)\n",
    "    df['UP_average_pos_in_cart'] = (df.z.map(userXproduct.sum_pos_in_cart) / df.UP_orders).astype(np.float32)\n",
    "    df['UP_reorder_rate'] = (df.UP_orders / df.user_total_orders).astype(np.float32)\n",
    "    df['UP_orders_since_last'] = df.user_total_orders - df.UP_last_order_id.map(orders.order_number)\n",
    "    df['UP_delta_hour_vs_last'] = abs(df.order_hour_of_day - df.UP_last_order_id.map(orders.order_hour_of_day)).map(\n",
    "        lambda x: min(x, 24 - x)).astype(np.int8)\n",
    "    # df['UP_same_dow_as_last_order'] = df.UP_last_order_id.map(orders.order_dow) == \\\n",
    "    #                                              df.order_id.map(orders.order_dow)\n",
    "\n",
    "    df.drop(['UP_last_order_id', 'z'], axis=1, inplace=True)\n",
    "    print(df.dtypes)\n",
    "    print(df.memory_usage())\n",
    "    return df, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# Training the lightGBM Model.\n",
    "# ====================================\n",
    "\n",
    "df_train, labels = features(train, labels_given=True)\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 96,\n",
    "    'max_depth': 10,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 5\n",
    "}\n",
    "ROUNDS = 100\n",
    "\n",
    "# Features to be trained on.\n",
    "features_to_train_on = ['user_total_orders', 'user_total_items', 'total_distinct_items',\n",
    "                        'user_average_days_between_orders', 'user_average_basket',\n",
    "                        'order_hour_of_day', 'days_since_prior_order', 'days_since_ratio',\n",
    "                        'aisle_id', 'department_id', 'product_orders', 'product_reorders',\n",
    "                        'product_reorder_rate', 'UP_orders', 'UP_orders_ratio',\n",
    "                        'UP_average_pos_in_cart', 'UP_reorder_rate', 'UP_orders_since_last',\n",
    "                        'UP_delta_hour_vs_last']\n",
    "\n",
    "# Preparing the input for the LightGBM model.\n",
    "d_train = lgb.Dataset(df_train[features_to_train_on],\n",
    "                      label=labels,\n",
    "                      categorical_feature=['aisle_id', 'department_id'])\n",
    "del df_train\n",
    "\n",
    "bst = lgb.train(params, d_train, ROUNDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# Testing the lightGBM Model.\n",
    "# ====================================\n",
    "\n",
    "df_test, _ = features(test)\n",
    "\n",
    "print('light GBM predict')\n",
    "preds = bst.predict(df_test[features_to_train_on])\n",
    "\n",
    "df_test['pred'] = preds\n",
    "\n",
    "# Applying thresholds on the predictions.\n",
    "TRESHOLD = 0.22  # guess, should be tuned with crossval on a subset of train data\n",
    "\n",
    "d = dict()\n",
    "for row in df_test.itertuples():\n",
    "    if row.pred > TRESHOLD:\n",
    "        try:\n",
    "            d[row.order_id] += ' ' + str(row.product_id)\n",
    "        except:\n",
    "            d[row.order_id] = str(row.product_id)\n",
    "\n",
    "for order in test.order_id:\n",
    "    if order not in d:\n",
    "        d[order] = 'None'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Submission.\n",
    "\n",
    "sub = pd.DataFrame.from_dict(d, orient='index')\n",
    "sub.reset_index(inplace=True)\n",
    "sub.columns = ['order_id', 'products']\n",
    "sub.to_csv('subs_samir.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# Approach три (Inspired by Second Place Approach Explanation in his blog post on Kaggle)\n",
    "# Link: http://blog.kaggle.com/2017/09/21/instacart-market-basket-analysis-winners-interview-2nd-place-kazuki-onodera/\n",
    "# ====================================\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
