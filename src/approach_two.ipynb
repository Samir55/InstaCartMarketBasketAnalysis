{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This code is rewritten and it's a modified fork from the base line proposed by Author : Paul-Antoine Nguyen which is\n",
    "# released under Apache 2.0 License.\n",
    "# Link: https://www.kaggle.com/paulantoine/light-gbm-benchmark-0-3692\n",
    "\n",
    "# We improved the performance of some parts of the original baseline code (it was too slow), we vecotrized some parts\n",
    "# to speedup the running time.\n",
    "\n",
    "# We added/removed features for the lightGBM classifier in order to improve the accuracy and test our method.\n",
    "# We added some features from the second place winner described in his blog post on Kaggle.\n",
    "\n",
    "# The Approach here is to tell for each previously purchased product for each user how likely he is going to purchase\n",
    "# it (binary classification). We used the train data frame as our labels and the priors for collecting features.\n",
    "\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# Reading the dataset.\n",
    "# ====================================\n",
    "\n",
    "aisles = pd.read_csv('data/aisles.csv')\n",
    "\n",
    "departments = pd.read_csv('data/departments.csv')\n",
    "\n",
    "# We are defining the type of each column to optimize the storage as far as we can.\n",
    "priors = pd.read_csv('data/order_products__prior.csv',\n",
    "                     dtype={\n",
    "                         'order_id': np.int32,\n",
    "                         'product_id': np.uint16,\n",
    "                         'add_to_cart_order': np.int16,  # The order of an added item to the cart.\n",
    "                         'reordered': np.int8}  # Whether the item has been reordered in the past.\n",
    "                     )\n",
    "\n",
    "train = pd.read_csv('data/order_products__train.csv',\n",
    "                    dtype={\n",
    "                        'order_id': np.int32,\n",
    "                        'product_id': np.uint16,\n",
    "                        'add_to_cart_order': np.int16,\n",
    "                        'reordered': np.int8}\n",
    "                    )\n",
    "\n",
    "orders = pd.read_csv('data/orders.csv',\n",
    "                     dtype={\n",
    "                         'order_id': np.int32,\n",
    "                         'user_id': np.int32,\n",
    "                         'eval_set': 'category',  # Categorical column.\n",
    "                         'order_number': np.int16,\n",
    "                         'order_dow': np.int8,\n",
    "                         'order_hour_of_day': np.int8,\n",
    "                         'days_since_prior_order': np.float32},\n",
    "                     )\n",
    "\n",
    "products = pd.read_csv('data/products.csv',\n",
    "                       dtype={\n",
    "                           'product_id': np.uint16,\n",
    "                           'order_id': np.int32,\n",
    "                           'aisle_id': np.uint8,\n",
    "                           'department_id': np.uint},\n",
    "                       usecols=['product_id', 'aisle_id', 'department_id']  # Ignore the product Name., It's not \n",
    "                       # required in our case \n",
    "                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32434489, 4)\n(1384617, 4)\n(49688, 3)\n(32434489, 4)\n(3421083, 7)\n\n=======Priors table head=======\n\n   order_id  product_id  add_to_cart_order  reordered\n0         2       33120                  1          1\n1         2       28985                  2          1\n2         2        9327                  3          0\n3         2       45918                  4          1\n4         2       30035                  5          0\n5         2       17794                  6          1\n6         2       40141                  7          1\n\n=======Train table head=======\n\n   order_id  product_id  add_to_cart_order  reordered\n0         1       49302                  1          1\n1         1       11109                  2          1\n2         1       10246                  3          0\n3         1       49683                  4          0\n4         1       43633                  5          1\n5         1       13176                  6          0\n6         1       47209                  7          0\n\n=======Orders table head=======\n\n   order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n0   2539329        1    prior             1          2                  8   \n1   2398795        1    prior             2          3                  7   \n2    473747        1    prior             3          3                 12   \n3   2254736        1    prior             4          4                  7   \n4    431534        1    prior             5          4                 15   \n5   3367565        1    prior             6          2                  7   \n6    550135        1    prior             7          1                  9   \n\n   days_since_prior_order  \n0                     NaN  \n1                    15.0  \n2                    21.0  \n3                    29.0  \n4                    28.0  \n5                    19.0  \n6                    20.0  \n\n=======Products table head=======\n\n   product_id  aisle_id  department_id\n0           1        61             19\n1           2       104             13\n2           3        94              7\n3           4        38              1\n4           5         5             13\n5           6        11             11\n6           7        98              7\n"
     ]
    }
   ],
   "source": [
    "# Print some information about the dataset.\n",
    "print(priors.shape)\n",
    "print(train.shape)\n",
    "print(products.shape)\n",
    "print(priors.shape)\n",
    "print(orders.shape)\n",
    "\n",
    "print(\"\\n=======Priors table head=======\\n\")\n",
    "print(priors.head(n=7))\n",
    "\n",
    "print(\"\\n=======Train table head=======\\n\")\n",
    "print(train.head(n=7))\n",
    "\n",
    "print(\"\\n=======Orders table head=======\\n\")\n",
    "print(orders.head(n=7))\n",
    "\n",
    "print(\"\\n=======Products table head=======\\n\")\n",
    "print(products.head(n=7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n=======Products table isNan checks =======\n\nproduct_id       0\naisle_id         0\ndepartment_id    0\ndtype: int64\n\n=======Train table isNan checks =======\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id             0\nproduct_id           0\nadd_to_cart_order    0\nreordered            0\ndtype: int64\n\n=======Priors table isNan checks =======\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id             0\nproduct_id           0\nadd_to_cart_order    0\nreordered            0\ndtype: int64\n\n=======Orders table isNan checks =======\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                       0\nuser_id                        0\neval_set                       0\norder_number                   0\norder_dow                      0\norder_hour_of_day              0\ndays_since_prior_order    206209\ndtype: int64\nNans percentage: 6.03%\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# Data Cleaning.\n",
    "# ====================================\n",
    "\n",
    "orders.set_index('order_id', drop=False, inplace=True)  # inplace means don't create a new object\n",
    "\n",
    "# Checking and removing Nans if found.\n",
    "print(\"\\n=======Products table isNan checks =======\\n\")\n",
    "print(np.sum(pd.isna(products)))\n",
    "\n",
    "print(\"\\n=======Train table isNan checks =======\\n\")\n",
    "print(np.sum(pd.isna(train)))\n",
    "\n",
    "print(\"\\n=======Priors table isNan checks =======\\n\")\n",
    "print(np.sum(pd.isna(priors)))\n",
    "\n",
    "print(\"\\n=======Orders table isNan checks =======\\n\")\n",
    "print(np.sum(pd.isna(orders)))\n",
    "\n",
    "# Found Nans only in the days_since_prior_order column in the orders table and replacing.\n",
    "print(\"Nans percentage: %.2f%%\" % (206209 / 3421083 * 100))\n",
    "orders['days_since_prior_order'] = orders['days_since_prior_order'].fillna(np.mean(orders['days_since_prior_order']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pandas/core/frame.py:6336: FutureWarning: 'product_id' is both an index level and a column label.\nDefaulting to column, but this will raise an ambiguity error in a future version\n  rsuffix=rsuffix, sort=sort)\n"
     ]
    }
   ],
   "source": [
    "# Approach Two\n",
    "# ====================================\n",
    "\n",
    "# ====================================\n",
    "# Adding Features to Products.\n",
    "# ====================================\n",
    "\n",
    "# Add New Features to the Products table.\n",
    "# The reorder rate.\n",
    "prod_features = pd.DataFrame()\n",
    "prod_features['freq'] = priors.groupby(priors.product_id).size().astype(np.int32)\n",
    "prod_features['reorder_freq'] = priors.reordered.groupby(priors.product_id).sum().astype(np.int32)\n",
    "prod_features['reorder_rate'] = (prod_features.reorder_freq / prod_features.freq).astype(np.float)\n",
    "\n",
    "products = products.join(prod_features, on='product_id')\n",
    "products.set_index('product_id', drop=False, inplace=True)\n",
    "del prod_features\n",
    "\n",
    "# Join prior with orders\n",
    "priors = priors.join(orders, on='order_id', rsuffix='_')\n",
    "priors.drop('order_id_', axis=1, inplace=True)  # Remove the order_id_ redundant column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# Adding Features to Users.\n",
    "# ====================================\n",
    "\n",
    "usrs = pd.DataFrame()\n",
    "usrs['avg_between_interval'] = orders.groupby('user_id')['days_since_prior_order'].mean().astype(np.float)\n",
    "usrs['orders_count'] = orders.groupby('user_id').size().astype(np.int16)\n",
    "usrs['avg_hour'] = orders.groupby('user_id')['order_hour_of_day'].mean().astype(np.int16)\n",
    "\n",
    "users = pd.DataFrame()\n",
    "users['total_items'] = priors.groupby('user_id').size().astype(np.int16)  # The count of all purchased items.\n",
    "users['all_products'] = priors.groupby('user_id')['product_id'].apply(set)  # A set of distinct products.\n",
    "users['all_distinct_products'] = users.all_products.map(len).astype(np.int16)  # The count of distinct products.\n",
    "\n",
    "users = users.join(usrs)\n",
    "del usrs\n",
    "\n",
    "users['average_basket'] = (users.total_items / users.orders_count).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add product id related to each user\n",
    "\n",
    "# (Slow Method)\n",
    "# priors['user_product'] = priors.product_id + priors.user_id * 1000000\n",
    "# # Creating a list of unique products bought by each user and the last time the user has bought it.\n",
    "# dic = dict()\n",
    "# for record in priors.itertuples():\n",
    "#     user_product_id = record.user_product\n",
    "#     if user_product_id not in dic:\n",
    "#         dic[user_product_id] = (1,  # means bought once\n",
    "#                                 (record.order_number, record.order_id),\n",
    "#                                 record.add_to_cart_order\n",
    "#                                 )\n",
    "#     else:\n",
    "#         dic[user_product_id] = (dic[user_product_id][0] + 1,\n",
    "#                                 max(dic[user_product_id][1], (record.order_number, record.order_id)),\n",
    "#                                 dic[user_product_id][2] + record.add_to_cart_order\n",
    "#                                 )\n",
    "#\n",
    "# user_product = pd.DataFrame.from_dict(dic,\n",
    "#                                       orient='index')  # Index means that the keys of the dictionary should be the\n",
    "# # rows not columns\n",
    "# del dic\n",
    "# user_product.columns = ['orders_count', 'last_order_id', 'sum_pos_in_cart']\n",
    "# user_product.orders_count = user_product.orders_count.astype(np.int16)\n",
    "# user_product.last_order_id = user_product.last_order_id.map(lambda x: x[1]).astype(np.int32)\n",
    "# user_product.sum_pos_in_cart = user_product.sum_pos_in_cart.astype(np.int16)\n",
    "# # We are not now in the need of the priors table.\n",
    "# del priors\n",
    "\n",
    "# Vectorized method.\n",
    "user_product = priors.copy()\n",
    "user_product['user_product'] = (user_product.product_id + user_product.user_id * 1000000).astype(np.int64)\n",
    "user_product = user_product.sort_values('order_number')\n",
    "user_product = user_product \\\n",
    "    .groupby('user_product', sort=False) \\\n",
    "    .agg({'order_id': ['size', 'last'], 'add_to_cart_order': 'sum'})\n",
    "user_product.columns = ['orders_count', 'last_order_id', 'sum_pos_in_cart']\n",
    "user_product.astype(\n",
    "    {'orders_count': np.int16, 'last_order_id': np.int32, 'sum_pos_in_cart': np.int16},\n",
    "    inplace=True)\n",
    "\n",
    "del priors\n",
    "\n",
    "# Printing some stats\n",
    "print(\"UserProduct table shape and first 7 rows\")\n",
    "print(user_product.shape)\n",
    "print(user_product.head(n=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# Creating Training and Testing splits.\n",
    "# ====================================\n",
    "\n",
    "train_orders = orders[orders.eval_set == 'train']\n",
    "test_orders = orders[orders.eval_set == 'test']\n",
    "\n",
    "train.set_index(['order_id', 'product_id'], inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(selected_orders, labels_given=False):\n",
    "    orders_l = []\n",
    "    products_l = []\n",
    "    labels = []\n",
    "\n",
    "    for i, _record in enumerate(tqdm(selected_orders.itertuples())):\n",
    "        # Get the order id\n",
    "        order_id = _record.order_id\n",
    "        user_id = _record.user_id\n",
    "        user_prods = users.all_products[user_id]\n",
    "\n",
    "        # Generate pairs of the previously purchased products of user and the current order id in the training table.\n",
    "        products_l.extend(user_prods)\n",
    "        orders_l.extend([order_id] * len(user_prods))\n",
    "\n",
    "        if labels_given:\n",
    "            # Generate a labels, put 1 in front of each previously purchased product of each user if it's found in the\n",
    "            # training table product list.\n",
    "            labels.extend([((order_id, prod_id) in train.index) for prod_id in user_prods])\n",
    "\n",
    "    # Create the Input for our classifier. Where we should create\n",
    "    x = pd.DataFrame({'order_id': orders_l, 'product_id': products_l})\n",
    "\n",
    "    # Create the labels for each tuple for x data frame.\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    del products_l\n",
    "    del orders_l\n",
    "\n",
    "    # Feature Engineering.\n",
    "\n",
    "    # The user features TODO @Samir55 Add more\n",
    "    x['user_id'] = x.order_id.map(orders.user_id)  # Add the user id column.\n",
    "    x['user_total_items'] = x.user_id.map(users.total_items)\n",
    "    x['user_total_orders'] = x.user_id.map(users.orders_count)\n",
    "    x['user_avg_days_between_orders'] = x.user_id.map(users.avg_between_interval)\n",
    "    x['user_avg_basket'] = x.user_id.map(users.average_basket)\n",
    "    x['user_avg_hour_of_day'] = x.user_id.map(users.avg_hour)\n",
    "\n",
    "    # The products features. TODO @Samir55 Add more\n",
    "    x['aisle_id'] = x.product_id.map(products.aisle_id)\n",
    "    x['department_id'] = x.product_id.map(products.department_id)\n",
    "    x['product_freq'] = x.product_id.map(products.freq)\n",
    "    x['product_reorder_freq'] = x.product_id.map(products.reorder_freq)\n",
    "    x['product_reorder_rate'] = x.product_id.map(products.reorder_rate)\n",
    "\n",
    "    # The order features. TODO @Samir55 Add more\n",
    "    x['order_hour_of_day'] = x.order_id.map(orders.order_hour_of_day)\n",
    "    x['order_day_of_week'] = x.order_id.map(orders.order_dow)\n",
    "    x['days_since_prior_order'] = x.order_id.map(orders.days_since_prior_order)\n",
    "\n",
    "    # The user_product features. TODO @Samir55 Add more\n",
    "    x['user_product_id'] = x.user_id * 1000000 + x.product_id\n",
    "    x.drop(['user_id'], inplace=True, axis=1)  # Remove user_id column and we will be using the user_product_id instead.\n",
    "    x['user_product_orders_count'] = x.user_product_id.map(user_product.orders_count)\n",
    "    # x['user_product_last_order_id'] = x.user_product_id.map(user_product.last_order_id)\n",
    "    x['user_product_avg_pos_in_cart'] = (\n",
    "            x.user_product_id.map(user_product.sum_pos_in_cart) / x.user_product_orders_count).astype(\n",
    "        np.float)\n",
    "    x['user_product_reorder_rate'] = (x.user_product_orders_count / x.user_total_orders).astype(np.float)\n",
    "\n",
    "    print(x.memory_usage())\n",
    "    return x, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# Training the lightGBM Model.\n",
    "# ====================================\n",
    "\n",
    "df_train, labels = features(train_orders, labels_given=True)\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 96,\n",
    "    'max_depth': 10,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 5\n",
    "}\n",
    "ROUNDS = 100\n",
    "\n",
    "# Features to be trained on.\n",
    "features_to_train_on = [\n",
    "    # User Features\n",
    "    'user_total_items',\n",
    "    'user_total_orders',  # 'total_distinct_items',\n",
    "    'user_avg_days_between_orders',\n",
    "    'user_avg_basket',\n",
    "    'user_avg_hour_of_day',\n",
    "\n",
    "    # Product Features\n",
    "    'aisle_id',\n",
    "    'department_id',\n",
    "    'product_freq',\n",
    "    'product_reorder_freq',\n",
    "    'product_reorder_rate',\n",
    "\n",
    "    # Order Features\n",
    "    'order_hour_of_day',\n",
    "    'order_day_of_week',\n",
    "    'days_since_prior_order',\n",
    "\n",
    "    # User_product Features.\n",
    "    'user_product_orders_count',\n",
    "    'user_product_avg_pos_in_cart',\n",
    "    'user_product_avg_pos_in_cart'\n",
    "]\n",
    "\n",
    "# Preparing the input for the LightGBM model.\n",
    "d_train = lgb.Dataset(df_train[features_to_train_on],\n",
    "                      label=labels,\n",
    "                      categorical_feature=['aisle_id', 'department_id'])\n",
    "del df_train\n",
    "\n",
    "bst = lgb.train(params, d_train, ROUNDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# Testing the lightGBM Model.\n",
    "# ====================================\n",
    "\n",
    "df_test, _ = features(test_orders)\n",
    "\n",
    "print('light GBM predict')\n",
    "preds = bst.predict(df_test[features_to_train_on])\n",
    "\n",
    "df_test['pred'] = preds\n",
    "\n",
    "# Applying thresholds on the predictions.\n",
    "TRESHOLD = 0.18  # by trials\n",
    "\n",
    "d = dict()\n",
    "for row in df_test.itertuples():\n",
    "    if row.pred > TRESHOLD:\n",
    "        try:\n",
    "            d[row.order_id] += ' ' + str(row.product_id)\n",
    "        except:\n",
    "            d[row.order_id] = str(row.product_id)\n",
    "\n",
    "for order in test_orders.order_id:\n",
    "    if order not in d:\n",
    "        d[order] = 'None'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Submission.\n",
    "\n",
    "sub = pd.DataFrame.from_dict(d, orient='index')\n",
    "sub.reset_index(inplace=True)\n",
    "sub.columns = ['order_id', 'products']\n",
    "sub.to_csv('subs_samir.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
